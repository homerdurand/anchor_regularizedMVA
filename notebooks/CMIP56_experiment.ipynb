{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f62fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "from matplotlib import gridspec\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy import signal\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV\n",
    "from sklearn.cross_decomposition import PLSRegression, CCA\n",
    "from sklearn.decomposition import FactorAnalysis, PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from MVA_algo_v2 import ReducedRankRegressor as RRR\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from data_treatment_tools import *\n",
    "from anchor_models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0178b159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ICML matplolib style\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from tueplots import bundles\n",
    "\n",
    "bundles.icml2022()\n",
    "{'text.usetex': True, 'font.family': 'serif', 'text.latex.preamble': '\\\\usepackage{times} ', 'figure.figsize': (3.25, 2.0086104634371584), 'figure.constrained_layout.use': True, 'figure.autolayout': False, 'savefig.bbox': 'tight', 'savefig.pad_inches': 0.015, 'font.size': 8, 'axes.labelsize': 8, 'legend.fontsize': 6, 'xtick.labelsize': 6, 'ytick.labelsize': 6, 'axes.titlesize': 8}\n",
    "\n",
    "bundles.icml2022(family=\"sans-serif\", usetex=False, column=\"full\", nrows=2)\n",
    "{'text.usetex': False, 'font.serif': ['Times'], 'mathtext.fontset': 'stix', 'mathtext.rm': 'Times', 'mathtext.it': 'Times:italic', 'mathtext.bf': 'Times:bold', 'font.family': 'sans-serif', 'figure.figsize': (6.75, 8.343458848123582), 'figure.constrained_layout.use': True, 'figure.autolayout': False, 'savefig.bbox': 'tight', 'savefig.pad_inches': 0.015, 'font.size': 8, 'axes.labelsize': 8, 'legend.fontsize': 6, 'xtick.labelsize': 6, 'ytick.labelsize': 6, 'axes.titlesize': 8}\n",
    "\n",
    "\n",
    "# Plug any of those into either the rcParams or into an rc_context:\n",
    "\n",
    "plt.rcParams.update(bundles.icml2022())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c953473",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as mcolors\n",
    "# Create a colormap object using 'coolwarm'\n",
    "cmap = plt.cm.get_cmap('coolwarm')\n",
    "blue_rgba1, blue_rgba2, red_rgba1, red_rgba2 = cmap(0.1), cmap(0.25), cmap(0.75), cmap(0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5b89d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'cmip56_data_coarse3_year.pkl' #File containing the model runs\n",
    "directory = '../data/' \n",
    "# Selecting low DIV for train and high DIV for test\n",
    "models_train_full = ['CCSM4', 'NorCPM1', 'CESM2', 'HadCM3']\n",
    "models_test = ['CNRM-CM6-1', 'CNRM-ESM2-1', 'IPSL-CM6A-LR']  #'IPSL-CM6A-LR', \n",
    "models = models_train_full + models_test\n",
    "with open(directory+file_name, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# Loading useful variables\n",
    "time = data['time']\n",
    "lon = data['lon']\n",
    "lat = data['lat']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffc57c0",
   "metadata": {},
   "source": [
    "### Computing DIV and GMT\n",
    "* We extract the local cliamte response by averaging over all runs in each model*\n",
    "* We obtain the Global response *gmt* by averaging the local responses spatially\n",
    "* Decadal Internal Variability is computed by substracting the global response to the global temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4c6132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters of DIV, RMT and RIV\n",
    "n_lat, n_lon, window_size = 30, 60, 10\n",
    "\n",
    "# Adding ensemble average of tas (ea_tas) and global mean temperature (gmt)\n",
    "for model in models :\n",
    "    data[model]['ea_tas'] = data[model]['tas'].mean(axis=0)\n",
    "    data[model]['gmt'] = data[model]['ea_tas'].mean(axis=(1, 2))\n",
    "\n",
    "    \n",
    "# Adding Decaal Internal Variability (div), Regional Mean Temperature (rmt) and Regional Internal variability (riv)\n",
    "for model in models:\n",
    "    div = decadalInternalVariability(data[model]['tas'], data[model]['gmt'])\n",
    "    rmt, riv = regionalMeanTemperature(data[model]['tas'], n_lat, n_lon, window_size)\n",
    "    data[model]['div'] = div\n",
    "    data[model]['rmt'] = rmt\n",
    "    data[model]['riv'] = riv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce197876",
   "metadata": {},
   "source": [
    "# Fingerprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceaccf1c",
   "metadata": {},
   "source": [
    "## Regional climate response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc8858c",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = 40\n",
    "regional_trends = {}\n",
    "for model in models:\n",
    "    shape = data[model]['rmt'].shape\n",
    "    Y = data[model]['rmt'][-years:,:,:].reshape(years, shape[1]*shape[2])\n",
    "    X = np.arange(Y.shape[0])[:,None]\n",
    "    trend = LinearRegression().fit(X, Y).coef_.reshape(shape[1], shape[2])\n",
    "    regional_trends[model] = np.array(trend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2624d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree())\n",
    "\n",
    "contour = ax.pcolormesh(lon, lat, regional_trends[models[0]], transform=ccrs.PlateCarree(), cmap='coolwarm')\n",
    "\n",
    "# Add coastlines and gridlines\n",
    "ax.coastlines()\n",
    "gl = ax.gridlines(draw_labels=True)\n",
    "gl.top_labels = gl.right_labels = False\n",
    "gl.xformatter = LONGITUDE_FORMATTER\n",
    "gl.yformatter = LATITUDE_FORMATTER\n",
    "\n",
    "plt.colorbar(contour, ax=ax, label='Error')\n",
    "\n",
    "plt.title('Mean Error of ML Model on Temperature Predictions')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ee5c2a",
   "metadata": {},
   "source": [
    "* We can see here that the temperature trends have a clear pattern. They are bigger in the poles (especially in the nothern pole) and lower when getting close to the equator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d9fda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_data(data, models, n_sample=1000, window_size=None):\n",
    "    A = None\n",
    "    for model in models:\n",
    "        # Extracting data\n",
    "        A_temp, X_temp, Y_temp = extract_data(data, model, window_size=None)\n",
    "        selected_idx = random.sample(range(A_temp.shape[0]), n_sample)\n",
    "        A_temp, X_temp, Y_temp = A_temp[selected_idx,:], X_temp[selected_idx,:], Y_temp[selected_idx,:]\n",
    "        if A is None :\n",
    "            A, X, Y = A_temp, X_temp, Y_temp\n",
    "        else :\n",
    "            A, X, Y = np.vstack((A, A_temp)), np.vstack((X, X_temp)), np.vstack((Y, Y_temp))\n",
    "    return A, X, Y\n",
    "\n",
    "def extract_data(data, model, n_lat_riv=None, n_lon_riv=None, window_size=None) :\n",
    "    shape = data[model]['tas'].shape\n",
    "    shape_rmt = data[model]['rmt'].shape\n",
    "    \n",
    "    Y = np.array([data[model]['rmt'] for i in range(shape[0])]).reshape(shape[0] * shape_rmt[0], shape_rmt[1]*shape_rmt[2])\n",
    "    X = data[model]['tas'].reshape(shape[0] * shape[1], shape[2]*shape[3])\n",
    "    A = data[model]['div'].reshape(shape[0] * shape[1], 1)\n",
    "\n",
    "    if window_size is not None:\n",
    "        # Create a 1D convolution kernel for the moving average\n",
    "        kernel = np.ones(window_size) / window_size\n",
    "        # Apply the moving average along axis=1\n",
    "        Y = np.apply_along_axis(lambda x: np.convolve(x, kernel, mode='same'), axis=1, arr=Y)\n",
    "\n",
    "    return A, X, Y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6e32e4",
   "metadata": {},
   "source": [
    "## Generating the train/test split\n",
    "* We generate a set of training and validation models by randomly selecting two of the training models (used to train RRRR) and the two others are left for validation. \n",
    "* This procedure is run $B=10$ times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a74f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 10\n",
    "train_val_split = []\n",
    "for b in range(B):\n",
    "    idx_train = random.sample(range(len(models_train_full)), len(models_train_full)//2)\n",
    "    idx_val = list(set(range(len(models_train_full))) - set(idx_train))\n",
    "    train, val = [models_train_full[i] for i in idx_train], [models_train_full[i] for i in idx_val]\n",
    "    train_val_split.append((train, val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee11ab8",
   "metadata": {},
   "source": [
    "* We sequence the hyperpapramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd9cc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting hyperparameters\n",
    "sep_rank, min_rank, max_rank = 20, 200, 600\n",
    "ranks = np.arange(min_rank, max_rank+1, sep_rank)\n",
    "n_rank = len(ranks)\n",
    "\n",
    "n_alpha = 20\n",
    "alphas = np.logspace(0, 5, n_alpha)\n",
    "n_sample = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cf0759",
   "metadata": {},
   "source": [
    "* For each of the train/validation split we train an RRRR model for each combination of hyperparameters and validate it by computing the R2 score and the Mean correaltion between DIV and residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37536cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stroring the MSE \n",
    "MSE_models = {'val' : [], 'train' : []}\n",
    "for models_train, models_val in tqdm(train_val_split):\n",
    "    # Extracting training/validation data\n",
    "    A_train, X_train, Y_train = extract_all_data(data, models_train, n_sample=n_sample)\n",
    "    A_val, X_val, Y_val = extract_all_data(data, models_val, n_sample=n_sample)\n",
    "    # Normalizing data\n",
    "    X_mean, Y_mean, A_mean = X_train.mean(axis=0), Y_train.mean(axis=0), A_train.mean(axis=0)\n",
    "    X_std, Y_std, A_std = X_train.std(axis=0), Y_train.std(axis=0), A_train.std(axis=0)\n",
    "    X_train_scaled, Y_train_scaled, A_train_scaled = (X_train - X_mean)/X_std, (Y_train - Y_mean)/Y_std, (A_train - A_mean)/A_std\n",
    "    X_val_scaled, Y_val_scaled, A_val_scaled = (X_val - X_mean)/X_std, (Y_val - Y_mean)/Y_std, (A_val - A_mean)/A_std\n",
    "\n",
    "    # Storing metrics \n",
    "    MSEs_val, MSE_PAs_val = np.zeros((n_rank, n_alpha)), np.zeros((n_rank, n_alpha))\n",
    "    MSEs_train, MSE_PAs_train = np.zeros((n_rank, n_alpha)), np.zeros((n_rank, n_alpha))\n",
    "    \n",
    "    # Looping on hyperparameters (gamma and alpha)\n",
    "    for i, rank in enumerate(ranks):\n",
    "        for j, alpha in enumerate(alphas):\n",
    "            # training a ridge model\n",
    "            ridge = ReducedRankRegressor(rank=rank, reg=alpha)\n",
    "            ridge.fit(X_train_scaled, Y_train_scaled)\n",
    "            Y_pred_val = ridge.predict(X_val_scaled)\n",
    "            Y_pred_train = ridge.predict(X_train_scaled)\n",
    "            \n",
    "            MSEs_val[i, j] = r2_score(Y_val_scaled, Y_pred_val)\n",
    "            MSEs_train[i, j] = r2_score(Y_train_scaled, Y_pred_train)\n",
    "            \n",
    "    MSE_models['val'].append(MSEs_val)\n",
    "    MSE_models['train'].append(MSEs_train)\n",
    "            \n",
    "# Averaging the scores\n",
    "MSE_models['val'], MSE_models['train'] = np.array(MSE_models['val']), np.array(MSE_models['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107e6a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_models_mean = MSE_models['val'].mean(axis=0)\n",
    "MSE_models_mean_train = MSE_models['train'].mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9de092",
   "metadata": {},
   "source": [
    "* We select the optimal hyperparameters such that they minimize the $R^2$ score in validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a6feaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "xticklabels = ['{:.0e}'.format(i) for i in alphas[6:]]\n",
    "yticklabels = ['{:.1e}'.format(i) for i in ranks]\n",
    "\n",
    "plt.figure(figsize=(16, 4))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title('MSE')\n",
    "sns.heatmap(MSE_models_mean, xticklabels=xticklabels, yticklabels=yticklabels)\n",
    "plt.xticks(fontsize=15, rotation =90)\n",
    "plt.yticks(fontsize=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad37e4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_idxs = np.unravel_index(MSE_models_mean.argmax(), MSE_models_mean.shape)\n",
    "optimal_params = ranks[optimal_idxs[0]], alphas[optimal_idxs[1]]\n",
    "\n",
    "print(\"Optimal hyperparameters (validation) :\\n    * rank = {}\\n    * alpha = {}\".format(optimal_params[0], optimal_params[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1f76b2",
   "metadata": {},
   "source": [
    "* We repeat the same procedure but now using the optimal hyperparameters selected above and use different values of $\\gamma$ to assess the performance of anchor-regularized RRRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41132a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gamma = 20\n",
    "gammas = np.logspace(0, 2, n_gamma)\n",
    "gammas[7] = 5\n",
    "# Stroring the MSE and MSE projected in the span of A (MSE_PA)\n",
    "metrics = {'rrrr' : {'corr' : [], 'r2' : []}, 'anchor' : { gamma : {'corr' : [], 'r2' : []} for gamma in gammas}}\n",
    "metrics_val = {'rrrr' : {'corr' : [], 'r2' : []}, 'anchor' : { gamma : {'corr' : [], 'r2' : []} for gamma in gammas}}\n",
    "\n",
    "res_models = []\n",
    "for models_train, models_val in tqdm(train_val_split):\n",
    "    # Extracting training/validation data\n",
    "    A_train, X_train, Y_train = extract_all_data(data, models_train, n_sample=n_sample)\n",
    "    A_val, X_val, Y_val = extract_all_data(data, models_val, n_sample=n_sample)\n",
    "    A_test, X_test, Y_test = extract_all_data(data, models_test, n_sample=n_sample)\n",
    "    \n",
    "    # Normalizing data\n",
    "    X_mean, Y_mean, A_mean = X_train.mean(axis=0), Y_train.mean(axis=0), A_train.mean(axis=0)\n",
    "    X_std, Y_std, A_std = X_train.std(axis=0), Y_train.std(axis=0), A_train.std(axis=0)\n",
    "    X_train_scaled, Y_train_scaled, A_train_scaled = (X_train - X_mean)/X_std, (Y_train - Y_mean)/Y_std, (A_train - A_mean)/A_std\n",
    "    X_val_scaled, Y_val_scaled, A_val_scaled = (X_val - X_mean)/X_std, (Y_val - Y_mean)/Y_std, (A_val - A_mean)/A_std\n",
    "    X_test_scaled, Y_test_scaled, A_test_scaled = (X_test - X_mean)/X_std, (Y_test - Y_mean)/Y_std, (A_test - A_mean)/A_std\n",
    "    \n",
    "    # Creating Projector in span of A to project residual (P_A) - will be use to compute MSE_PA\n",
    "    #P_A_val = A_val_scaled @ np.linalg.inv(A_val_scaled.T @ A_val_scaled) @ A_val_scaled.T\n",
    "    #P_A_test = A_test_scaled @ np.linalg.inv(A_test_scaled.T @ A_test_scaled) @ A_test_scaled.T\n",
    "\n",
    "    for gamma in gammas:\n",
    "        # Training a RRRR\n",
    "        anchor = ReducedRankRegressor(rank=optimal_params[0], reg=optimal_params[1])\n",
    "        # Projecting the training data in anchor space\n",
    "        AOP = AnchorOptimalProjection(gamma=gamma)\n",
    "        X_train_transform, Y_train_transform = AOP.fit_transform(A_train_scaled, X_train_scaled, Y_train_scaled)\n",
    "\n",
    "        # training a anchor model\n",
    "        anchor.fit(X_train_transform, Y_train_transform)\n",
    "        Y_pred_test_anchor = anchor.predict(X_test_scaled)\n",
    "        metrics['anchor'][gamma]['r2'].append(r2_score(Y_test_scaled, Y_pred_test_anchor))\n",
    "        metrics['anchor'][gamma]['corr'].append(np.array([np.corrcoef(a, res)[0, 1] for res in (Y_test_scaled - Y_pred_test_anchor).T for a in A_test_scaled.T]).mean())\n",
    "        \n",
    "        Y_pred_val_anchor = anchor.predict(X_val_scaled)\n",
    "        metrics_val['anchor'][gamma]['r2'].append(r2_score(Y_val_scaled, Y_pred_val_anchor))\n",
    "        metrics_val['anchor'][gamma]['corr'].append(np.array([np.corrcoef(a, res)[0, 1] for res in (Y_val_scaled - Y_pred_val_anchor).T for a in A_val_scaled.T]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4507c71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "values = np.array([metrics['anchor'][gamma]['r2'] for gamma in gammas]).T\n",
    "plt.boxplot(values)\n",
    "plt.xlabel(r'$\\gamma$', fontsize=20)\n",
    "plt.xticks(range(1, gammas.shape[0]+1), [round(gamma, 1) for gamma in gammas], rotation=45, fontsize=20)\n",
    "plt.ylabel(r'$R^2$', fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "directory = '/home/homer/Documents/Doctorado/Investigacion/AnchorMultivariateAnalysis/Results'\n",
    "plt.savefig(directory + \"/R2_score_alpha.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47d8139",
   "metadata": {},
   "source": [
    "* We can see that $\\forall \\gamma > 1$, anchor regularisation lead to better prediction performance on the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893b845b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "values = np.array([metrics['anchor'][gamma]['corr'] for gamma in gammas]).T\n",
    "plt.boxplot(values)\n",
    "plt.xlabel(r'$\\gamma$', fontsize=20)\n",
    "plt.xticks(range(1, gammas.shape[0]+1), [round(gamma, 1) for gamma in gammas], rotation=45, fontsize=20)\n",
    "plt.ylabel('Mean correlation between anchor and residuals', fontsize=16)\n",
    "plt.yticks(fontsize=20)\n",
    "directory = '/home/homer/Documents/Doctorado/Investigacion/AnchorMultivariateAnalysis/Results'\n",
    "plt.savefig(directory + \"/Correlation_score_alpha.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c168dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_scores = np.mean([metrics['anchor'][gamma]['r2'] for gamma in gammas], axis=1)\n",
    "mean_corr_scores = np.mean([metrics['anchor'][gamma]['corr'] for gamma in gammas], axis=1)\n",
    "metric05 = 0.5*r2_scores/r2_scores.std() - 0.5*mean_corr_scores/mean_corr_scores.std()\n",
    "metric09 = 0.9*r2_scores/r2_scores.std() - 0.1*mean_corr_scores/mean_corr_scores.std()\n",
    "argmin05, argmin09 = np.argmax(metric05), np.argmax(metric09)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc9d9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_scores_val = np.mean([metrics_val['anchor'][gamma]['r2'] for gamma in gammas], axis=1)\n",
    "mean_corr_scores_val = np.mean([metrics_val['anchor'][gamma]['corr'] for gamma in gammas], axis=1)\n",
    "metric05_val = 0.5*r2_scores_val/r2_scores_val.std() - 0.5*mean_corr_scores_val/mean_corr_scores_val.std()\n",
    "metric09_val = 0.9*r2_scores_val/r2_scores_val.std() - 0.1*mean_corr_scores_val/mean_corr_scores_val.std()\n",
    "argmin05_val, argmin09_val = np.argmax(metric05_val), np.argmax(metric09_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c1a6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Scatter plots\n",
    "plt.scatter(r2_scores[argmin05], mean_corr_scores[argmin05], c=red_rgba1, s=300, marker=\"D\", edgecolors='black', label=r'optimal $\\gamma$ $0.5/0.5$ (test)')\n",
    "plt.scatter(r2_scores[argmin09], mean_corr_scores[argmin09], c=red_rgba2, s=300, marker=\"D\", edgecolors='black', label=r'optimal $\\gamma$ $0.1/0.9$ (test)')\n",
    "plt.scatter(r2_scores[0], mean_corr_scores[0], c=red_rgba1, s=300, marker=\"^\", edgecolors='black', label=r'RRRR (test)')\n",
    "\n",
    "\n",
    "plt.scatter(r2_scores_val[argmin05_val], mean_corr_scores_val[argmin05_val], c=blue_rgba2, s=300, marker=\"D\", edgecolors='black', label=r'optimal $\\gamma$ $0.5/0.5$ (train)')\n",
    "plt.scatter(r2_scores_val[argmin09_val], mean_corr_scores_val[argmin09_val], c=blue_rgba1, s=300, marker=\"D\", edgecolors='black', label=r'optimal $\\gamma$ $0.1/0.9$ (train)')\n",
    "plt.scatter(r2_scores_val[0], mean_corr_scores_val[0], c=blue_rgba1, s=300, marker=\"^\", edgecolors='black', label=r'RRRR (train)')\n",
    "\n",
    "# Line plot\n",
    "plt.plot(r2_scores, mean_corr_scores, c=red_rgba1, marker='o', markersize=8, linewidth=4)\n",
    "plt.plot(r2_scores_val, mean_corr_scores_val, c=blue_rgba2, marker='o', markersize=8, linewidth=4)\n",
    "\n",
    "plt.ylabel('Mean correlation between DIV and residuals', fontsize=20)\n",
    "plt.xlabel(r'$R^2$', fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.xticks(fontsize=20)\n",
    "\n",
    "# Legend above the plot\n",
    "plt.legend(fontsize=20, loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=2)\n",
    "\n",
    "directory = '/home/homer/Documents/Doctorado/Investigacion/AnchorMultivariateAnalysis/Results'\n",
    "plt.savefig(directory + \"/pareto_gamma_opt_30x60.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a057b70a",
   "metadata": {},
   "source": [
    "* Anchor regularised RRRR show also a lower correlation between DIV and residuals "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cae89ab",
   "metadata": {},
   "source": [
    "# Scores maps\n",
    "We know train A-RRRR on the full set of training models with optimal $(\\alpha, r_r)$ parameters, now with only 250 samples for each model in order ot get the same number of samples as in validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfe2818",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 5\n",
    "res_map_anchor, corr_map_anchor = [], []\n",
    "res_map_rrrr, corr_map_rrrr = [], []\n",
    "\n",
    "B=10\n",
    "for b in tqdm(range(B)):\n",
    "    A_train, X_train, Y_train = extract_all_data(data, models_train_full, n_sample=n_sample//2)\n",
    "    #A_val, X_val, Y_val = extract_all_data(data, models_val, n_sample=n_sample)\n",
    "    A_test, X_test, Y_test = extract_all_data(data, models_test, n_sample=n_sample)\n",
    "\n",
    "    # Normalizing data\n",
    "    X_mean, Y_mean, A_mean = X_train.mean(axis=0), Y_train.mean(axis=0), A_train.mean(axis=0)\n",
    "    X_std, Y_std, A_std = X_train.std(axis=0), Y_train.std(axis=0), A_train.std(axis=0)\n",
    "    X_train_scaled, Y_train_scaled, A_train_scaled = (X_train - X_mean)/X_std, (Y_train - Y_mean)/Y_std, (A_train - A_mean)/A_std\n",
    "    #X_val_scaled, Y_val_scaled, A_val_scaled = (X_val - X_mean)/X_std, (Y_val - Y_mean)/Y_std, (A_val - A_mean)/A_std\n",
    "    X_test_scaled, Y_test_scaled, A_test_scaled = (X_test - X_mean)/X_std, (Y_test - Y_mean)/Y_std, (A_test - A_mean)/A_std\n",
    "    anchor = ReducedRankRegressor(rank=optimal_params[0], reg=optimal_params[1])\n",
    "    # Projecting the training data in anchor space\n",
    "    AOP = AnchorOptimalProjection(gamma=gamma)\n",
    "    X_train_transform, Y_train_transform = AOP.fit_transform(A_train_scaled, X_train_scaled, Y_train_scaled)\n",
    "\n",
    "    # training a anchor model\n",
    "    anchor.fit(X_train_transform, Y_train_transform)\n",
    "    Y_pred_test_anchor = anchor.predict(X_test_scaled)\n",
    "    res_anchor = Y_test_scaled - Y_pred_test_anchor\n",
    "    res_anchor_map = r2_score(Y_test_scaled, Y_pred_test_anchor, multioutput='raw_values').reshape(n_lat, n_lon)\n",
    "    corr_anchor = np.array([np.corrcoef(A_test_scaled[:,0], res)[0, 1] for res in res_anchor.T])\n",
    "    corr_anchor_map = corr_anchor.reshape(n_lat, n_lon)\n",
    "    \n",
    "    res_map_anchor.append(res_anchor_map)\n",
    "    corr_map_anchor.append(corr_anchor_map)\n",
    "    \n",
    "    # training a rrrr model\n",
    "    rrrr = ReducedRankRegressor(rank=optimal_params[0], reg=optimal_params[1])\n",
    "    rrrr.fit(X_train_scaled, Y_train_scaled)\n",
    "    Y_pred_test_rrrr = rrrr.predict(X_test_scaled)\n",
    "    res_rrrr = Y_test_scaled - Y_pred_test_rrrr\n",
    "    res_rrrr_map = r2_score(Y_test_scaled, Y_pred_test_rrrr, multioutput='raw_values').reshape(n_lat, n_lon)\n",
    "    corr_rrrr = np.array([np.corrcoef(A_test_scaled[:,0], res)[0, 1] for res in res_rrrr.T])\n",
    "    corr_rrrr_map = corr_rrrr.reshape(n_lat, n_lon)\n",
    "    \n",
    "    res_map_rrrr.append(res_rrrr_map)\n",
    "    corr_map_rrrr.append(corr_rrrr_map)\n",
    "\n",
    "res_map_anchor, corr_map_anchor = np.array(res_map_anchor), np.array(corr_map_anchor)\n",
    "res_map_rrrr, corr_map_rrrr = np.array(res_map_rrrr), np.array(corr_map_rrrr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dafa7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_map_anchor_mean, corr_map_anchor_mean = res_map_anchor.mean(axis=0), corr_map_anchor.mean(axis=0)\n",
    "res_map_rrrr_mean, corr_map_rrrr_mean = res_map_rrrr.mean(axis=0), corr_map_rrrr.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07ab516",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_r2_map = res_map_anchor_mean - res_map_rrrr_mean\n",
    "diff_corr_map = abs(corr_map_rrrr_mean) - abs(corr_map_anchor_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7fba6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "\n",
    "# Assuming you have defined lat, lon, diff_r2_map, diff_corr_map, max_val_r2, max_val_corr\n",
    "\n",
    "# Plotting\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20, 6), subplot_kw={'projection': ccrs.Robinson()})\n",
    "\n",
    "# Plot for diff_r2_map\n",
    "norm_r2 = plt.Normalize(vmin=-0.15, vmax=0.15)\n",
    "contour_r2 = axs[0].pcolormesh(lon, lat, diff_r2_map, transform=ccrs.PlateCarree(), cmap='coolwarm', norm=norm_r2)\n",
    "contour_r2_hatched = axs[0].contourf(lon, lat, diff_r2_map, levels=[0, max_val_r2], hatches=['.', None], colors='none', transform=ccrs.PlateCarree())\n",
    "axs[0].coastlines()\n",
    "gl_r2 = axs[0].gridlines(draw_labels=True)\n",
    "gl_r2.top_labels = gl_r2.right_labels = False\n",
    "gl_r2.xformatter = LONGITUDE_FORMATTER\n",
    "gl_r2.yformatter = LATITUDE_FORMATTER\n",
    "gl_r2.xlabel_style = {'size': 20}  # Longitude font size\n",
    "gl_r2.ylabel_style = {'size': 20}  # Latitude font size\n",
    "axs[0].set_title('A', fontsize=25)\n",
    "\n",
    "cb2 = fig.colorbar(contour_r2, ax=axs[0], label='R2 score differences', orientation='horizontal')\n",
    "cb2.ax.tick_params(labelsize=20)\n",
    "cb2.set_label(r'$\\Delta R^2$ ', fontsize=20) \n",
    "\n",
    "# Plot for diff_corr_map\n",
    "norm_corr = plt.Normalize(vmin=-0.4, vmax=0.4)\n",
    "contour_corr = axs[1].pcolormesh(lon, lat, diff_corr_map, transform=ccrs.PlateCarree(), cmap='coolwarm', norm=norm_corr)\n",
    "contour_corr_hatched = axs[1].contourf(lon, lat, diff_corr_map, levels=[0, max_val_corr], hatches=['.', None], colors='none', transform=ccrs.PlateCarree())\n",
    "axs[1].coastlines()\n",
    "gl_corr = axs[1].gridlines(draw_labels=True)\n",
    "gl_corr.top_labels = gl_corr.right_labels = False\n",
    "gl_corr.xformatter = LONGITUDE_FORMATTER\n",
    "gl_corr.yformatter = LATITUDE_FORMATTER\n",
    "\n",
    "gl_corr.xlabel_style = {'size': 20}  # Longitude font size\n",
    "gl_corr.ylabel_style = {'size': 20}  # Latitude font size\n",
    "axs[1].set_title('B', fontsize=25)\n",
    "\n",
    "cb2 = fig.colorbar(contour_corr, ax=axs[1], label='Residuals', orientation='horizontal')\n",
    "cb2.ax.tick_params(labelsize=20)\n",
    "cb2.set_label(r'$\\Delta r$', fontsize=20)  # Colorbar label font size\n",
    "\n",
    "directory = '/home/homer/Documents/Doctorado/Investigacion/AnchorMultivariateAnalysis/Results'\n",
    "plt.savefig(directory + \"/maps_R2_corr_30x60_gamma{}.pdf\".format(gamma), format=\"pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7dac3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "\n",
    "# Assuming you have defined lat, lon, diff_r2_map, diff_corr_map, max_val_r2, max_val_corr\n",
    "\n",
    "# Plotting\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20, 6), subplot_kw={'projection': ccrs.Robinson()})\n",
    "\n",
    "# Plot for diff_r2_map\n",
    "norm_r2 = TwoSlopeNorm(vmin=-0.4, vcenter=0, vmax=0.8)\n",
    "contour_r2 = axs[0].pcolormesh(lon, lat, res_map_anchor_mean, transform=ccrs.PlateCarree(), cmap='coolwarm', norm=norm_r2)\n",
    "axs[0].coastlines()\n",
    "gl_r2 = axs[0].gridlines(draw_labels=True)\n",
    "gl_r2.top_labels = gl_r2.right_labels = False\n",
    "gl_r2.xformatter = LONGITUDE_FORMATTER\n",
    "gl_r2.yformatter = LATITUDE_FORMATTER\n",
    "gl_r2.xlabel_style = {'size': 20}  # Longitude font size\n",
    "gl_r2.ylabel_style = {'size': 20}  # Latitude font size\n",
    "axs[0].set_title('A', fontsize=25)\n",
    "\n",
    "cb2 = fig.colorbar(contour_r2, ax=axs[0], label='R2 score differences', orientation='horizontal')\n",
    "cb2.ax.tick_params(labelsize=20)\n",
    "cb2.set_label(r'$R^2$', fontsize=20) \n",
    "\n",
    "# Plot for diff_corr_map\n",
    "norm_corr = plt.Normalize(vmin=-0.6, vmax=0.6)\n",
    "contour_corr = axs[1].pcolormesh(lon, lat, corr_map_anchor_mean, transform=ccrs.PlateCarree(), cmap='coolwarm', norm=norm_corr)\n",
    "axs[1].coastlines()\n",
    "gl_corr = axs[1].gridlines(draw_labels=True)\n",
    "gl_corr.top_labels = gl_corr.right_labels = False\n",
    "gl_corr.xformatter = LONGITUDE_FORMATTER\n",
    "gl_corr.yformatter = LATITUDE_FORMATTER\n",
    "\n",
    "gl_corr.xlabel_style = {'size': 20}  # Longitude font size\n",
    "gl_corr.ylabel_style = {'size': 20}  # Latitude font size\n",
    "axs[1].set_title('B', fontsize=25)\n",
    "\n",
    "cb2 = fig.colorbar(contour_corr, ax=axs[1], label='Residuals', orientation='horizontal')\n",
    "cb2.ax.tick_params(labelsize=20)\n",
    "cb2.set_label('Correlation between DIV and residuals', fontsize=20)  # Colorbar label font size\n",
    "\n",
    "directory = '/home/homer/Documents/Doctorado/Investigacion/AnchorMultivariateAnalysis/Results'\n",
    "plt.savefig(directory + \"/maps_anchor_R2_corr_30x60_gamma{}.pdf\".format(gamma), format=\"pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098f23f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "\n",
    "# Assuming you have defined lat, lon, diff_r2_map, diff_corr_map, max_val_r2, max_val_corr\n",
    "\n",
    "# Plotting\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20, 6), subplot_kw={'projection': ccrs.Robinson()})\n",
    "\n",
    "# Plot for diff_r2_map\n",
    "norm_r2 = TwoSlopeNorm(vmin=-0.4, vcenter=0, vmax=0.8)\n",
    "contour_r2 = axs[0].pcolormesh(lon, lat, res_map_rrrr_mean, transform=ccrs.PlateCarree(), cmap='coolwarm', norm=norm_r2)\n",
    "axs[0].coastlines()\n",
    "gl_r2 = axs[0].gridlines(draw_labels=True)\n",
    "gl_r2.top_labels = gl_r2.right_labels = False\n",
    "gl_r2.xformatter = LONGITUDE_FORMATTER\n",
    "gl_r2.yformatter = LATITUDE_FORMATTER\n",
    "gl_r2.xlabel_style = {'size': 20}  # Longitude font size\n",
    "gl_r2.ylabel_style = {'size': 20}  # Latitude font size\n",
    "axs[0].set_title('A', fontsize=25)\n",
    "\n",
    "cb2 = fig.colorbar(contour_r2, ax=axs[0], label='R2 score differences', orientation='horizontal')\n",
    "cb2.ax.tick_params(labelsize=20)\n",
    "cb2.set_label(r'$R^2$', fontsize=20) \n",
    "\n",
    "# Plot for diff_corr_map\n",
    "norm_corr = plt.Normalize(vmin=-0.6, vmax=0.6)\n",
    "contour_corr = axs[1].pcolormesh(lon, lat, corr_map_rrrr_mean, transform=ccrs.PlateCarree(), cmap='coolwarm', norm=norm_corr)\n",
    "axs[1].coastlines()\n",
    "gl_corr = axs[1].gridlines(draw_labels=True)\n",
    "gl_corr.top_labels = gl_corr.right_labels = False\n",
    "gl_corr.xformatter = LONGITUDE_FORMATTER\n",
    "gl_corr.yformatter = LATITUDE_FORMATTER\n",
    "\n",
    "gl_corr.xlabel_style = {'size': 20}  # Longitude font size\n",
    "gl_corr.ylabel_style = {'size': 20}  # Latitude font size\n",
    "axs[1].set_title('B', fontsize=25)\n",
    "\n",
    "cb2 = fig.colorbar(contour_corr, ax=axs[1], label='Residuals', orientation='horizontal')\n",
    "cb2.ax.tick_params(labelsize=20)\n",
    "cb2.set_label('Correlation between DIV and residuals', fontsize=20)  # Colorbar label font size\n",
    "\n",
    "directory = '/home/homer/Documents/Doctorado/Investigacion/AnchorMultivariateAnalysis/Results'\n",
    "plt.savefig(directory + \"/maps_rrrr_R2_corr_30x60.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e5906d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6c69e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
